{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinary Least Squares with Gradient Descent\n",
    "\n",
    "> Ordinary least squares, or linear regression, estimates the parameters in a regression model by minimizing the sum of the squared residuals.\n",
    ">\n",
    "> -- <cite>[(Frost, 2017)][1]</cite>\n",
    "\n",
    "In ordinary least squares  (OLS) we have a problem where we want to predict the value of a continuous variable $Y$ , using a set of independent variables $X_1, X_2,...X_n$.\n",
    "\n",
    "\n",
    "## The Problem Presentation\n",
    "\n",
    "Our linear regression problem will be presented as\n",
    "\n",
    "### $\\hat{Y} = b_0 + b_1X_1 + b_2X_2 +...+ b_nX_n $\n",
    "\n",
    "where $b_0, b_1,...b_n$ are model parameters (coefficients) and $\\hat{Y}$ represents the fitted values of Y.\n",
    "\n",
    "## The Objective or Fitness Function\n",
    "\n",
    "The objective function of OLS according to the definition above is to minimize the sum of squared residuals (SSR) where the difference between the predicted ($\\hat{Y}$) and observed ($Y$) values are called residuals. We can represent this mathematically\n",
    "\n",
    "### $min \\sum_{i=1}^m (\\hat{Y}^{(i)} - Y^{(i)})^2$\n",
    "\n",
    "where $m$ is the number of observations.\n",
    "\n",
    "## The Optimization Method\n",
    "\n",
    "We will be using gradient descent has the optimization strategy to obtain the optimal value for $b_0$ & $b_1$ for our regression line. We commonly represent our regression line as $y = b_0 + b_1x$ however since in machine learning we will be mainly dealing with matrices, I will denote my $y$ which is my hypothesis space as $J(\\theta)$ and rename the $b_0$ & $b_1$ coefficients to $\\theta_0$ & $\\theta_1$. Which gives us the machine learning version of our regression line\n",
    "\n",
    "### $J(\\theta) = \\theta_0 + \\theta_1X$\n",
    "\n",
    "where\n",
    "- $X$ is a matrix of size $m\\times(n+1)$ where column $k$, the first column of $X$, is populated with ones.\n",
    "- $\\theta$ is a sequence or vector of coefficents $(\\theta^0_0, \\theta^0_1), (\\theta^1_0, \\theta^1_1),..., (\\theta^i_0, \\theta^i_1)$\n",
    "\n",
    ">To explain in brief about gradient descent, imagine that you are on a mountain and are blindfolded and your task is to come down from the mountain to the flat land without assistance. The only assistance you have is a gadget which tells you the height from sea-level. What would be your approach be. You would start to descend in some random direction and then ask the gadget what is the height now. If the gadget tells you that height and it is more than the initial height then you know you started in wrong direction. You change the direction and repeat the process. This way in many iterations finally you successfully descend down.\n",
    ">\n",
    "> -- [(Sagar Mainkar, 2018)][2]\n",
    "\n",
    "In terms of machine learning the analogy translates as:\n",
    "\n",
    ">Size of steps took in any direction = Learning rate\n",
    "\n",
    ">Gadget tells you height = Cost function\n",
    "\n",
    ">The direction of your steps = Gradients\n",
    "\n",
    "### Cost Function\n",
    "In our cost function we use mean squared error (MSE) to calculate the cost over our training set. MSE is commonly used for regression evaluation and its the formula for MSE is\n",
    "\n",
    "### MSE = $\\frac{1}{N}\\sum_{i=1}^N (\\hat{Y}^{(i)} - Y^{(i)})^2$\n",
    "\n",
    "> MSE basically measures average squared error of our predictions. For each point, it calculates square difference between the predictions and the target and then average those values.\n",
    "The higher this value, the worse the model is. It is never negative, since weâ€™re squaring the individual prediction-wise errors before summing them, but would be zero for a perfect model.\n",
    ">\n",
    "> -- [(Drakos, 2018)][3]\n",
    "\n",
    "We will define our cost function as\n",
    "\n",
    "### $J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^m (\\hat{Y}^{(i)} - Y^{(i)})^2$\n",
    "\n",
    "where\n",
    "- $m$ is the number of observations.\n",
    "- $\\hat{Y}$ is the linear combination of the input features (x variables) and weights the $\\theta$\n",
    "\n",
    "> we multiply $\\frac{1}{2}$ with our MSE function to make the result from the next step (calculting the partial derivative) easier.\n",
    "\n",
    "### Gradient\n",
    "\n",
    "If we apply the partial derivative to our cost function with respect to parameter $\\theta$ which is a sequence or vector of coefficents of the form $(\\theta_0, \\theta_1)$ we get:\n",
    "\n",
    "### $\\frac{\\partial J}{\\partial\\theta_0} = \\frac{1}{m} \\sum_{i=1}^m (\\hat{Y}^{(i)} - Y^{(i)}) \\times X^{(i)}_0$\n",
    "\n",
    "- $\\theta_0$ is the coffecient bias or constant, essentially it is analogous to the $b_0$ in $\\hat{y} = b_0 + b_1\\times x_1$.\n",
    "- $X$ is a matrix filled with ones.\n",
    "- $X_0 = 1$ just like $x_0$ in $\\hat{y} = b_0 + b_1 \\times x_1$, so therefore our partial derivative $\\frac{\\partial J}{\\partial\\theta_0}$ can be simplified to\n",
    "\n",
    "### $\\frac{\\partial J}{\\partial\\theta_0} = \\frac{1}{m} \\sum_{i=1}^m (\\hat{Y}^{(i)} - Y^{(i)})$\n",
    "\n",
    "Now we apply the same logic for $\\theta_1$\n",
    "\n",
    "### $\\frac{\\partial J}{\\partial\\theta_1} = \\frac{1}{m} \\sum_{i=1}^m (\\hat{Y}^{(i)} - Y^{(i)}) \\times X^{(i)}_1$\n",
    "\n",
    "We are trying to minimize our cost function and to do that we would need to know the $\\theta$ at each step/iteration  computing the partial derivative of our cost function can give us the next $\\theta$.\n",
    "\n",
    "So now to compute the new values for $\\theta_0$ and $\\theta_1$ and even up to $\\theta_n$ we do the following:\n",
    "\n",
    "### $\\theta_0 = \\theta_0 - \\alpha \\times \\frac{1}{m} \\sum_{i=1}^m (\\hat{Y}^{(i)} - Y^{(i)}) \\times X^{(i)}_0$\n",
    "### $\\theta_1 = \\theta_1 - \\alpha \\times \\frac{1}{m} \\sum_{i=1}^m (\\hat{Y}^{(i)} - Y^{(i)}) \\times X^{(i)}_1$\n",
    "### $\\theta_2 = \\theta_2 - \\alpha \\times \\frac{1}{m} \\sum_{i=1}^m (\\hat{Y}^{(i)} - Y^{(i)}) \\times X^{(i)}_2$\n",
    ".....\n",
    "### $\\theta_n = \\theta_n - \\alpha \\times \\frac{1}{m} \\sum_{i=1}^m (\\hat{Y}^{(i)} - Y^{(i)}) \\times X^{(i)}_n$\n",
    "\n",
    "where $\\alpha$ is the learning rate\n",
    "\n",
    "[1]:http://statisticsbyjim.com/glossary/ordinary-least-squares/\n",
    "[2]:https://towardsdatascience.com/gradient-descent-in-python-a0d07285742f\n",
    "[3]:https://towardsdatascience.com/how-to-select-the-right-evaluation-metric-for-machine-learning-models-part-1-regrression-metrics-3606e25beae0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
